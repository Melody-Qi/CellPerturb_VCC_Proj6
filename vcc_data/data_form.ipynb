{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run every section seperatedly.\n",
    "\n",
    "since there are multiple variables in different sections that have the same name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detail information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件信息概览：\n",
      "{'path': 'adata_Training.h5ad', 'exists': True, 'size_bytes': 15482497461, 'size_human': '14.4 GB', 'mtime': 1762960875.5560176}\n",
      "{'path': 'gene_names.csv', 'exists': True, 'size_bytes': 116023, 'size_human': '113.3 KB', 'mtime': 1762957829.7691019}\n",
      "{'path': 'pert_counts_Validation.csv', 'exists': True, 'size_bytes': 978, 'size_human': '978.0 B', 'mtime': 1762957829.7691019}\n",
      "\n",
      "读取 anndata (.h5ad)...\n",
      "adata: AnnData object with n_obs × n_vars = 221273 × 18080\n",
      "    obs: 'target_gene', 'guide_id', 'batch'\n",
      "    var: 'gene_id'\n",
      "形状: n_obs=221273, n_vars=18080\n",
      "obs 列（前若干）: ['target_gene', 'guide_id', 'batch']\n",
      "var 列（前若干）: ['gene_id']\n",
      "X 子集(3x5)示例：\n",
      " [[0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "\n",
      "读取 gene_names.csv ...\n",
      "gene_names.csv 预览：\n",
      "    SAMD11\n",
      "0    NOC2L\n",
      "1   KLHL17\n",
      "2  PLEKHN1\n",
      "3    PERM1\n",
      "4     HES4\n",
      "列信息： ['SAMD11']\n",
      "行数/列数： (18079, 1)\n",
      "\n",
      "读取 pert_counts_Validation.csv ...\n",
      "pert_counts_Validation.csv 预览：\n",
      "  target_gene  n_cells  median_umi_per_cell\n",
      "0      SH3BP4     2925              54551.0\n",
      "1      ZNF581     2502              53803.5\n",
      "2       ANXA6     2496              55175.0\n",
      "3     PACSIN3     2101              54088.0\n",
      "4       MGST1     2096              54217.5\n",
      "列信息： ['target_gene', 'n_cells', 'median_umi_per_cell']\n",
      "行数/列数： (50, 3)\n",
      "\n",
      "读取完成。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "# anndata/scanpy 用于 .h5ad\n",
    "\n",
    "path_adata = \"adata_Training.h5ad\"\n",
    "path_gene  = \"gene_names.csv\"\n",
    "path_pert  = \"pert_counts_Validation.csv\"\n",
    "\n",
    "def human_size(n):\n",
    "    for unit in [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]:\n",
    "        if n < 1024:\n",
    "            return f\"{n:.1f} {unit}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.1f} PB\"\n",
    "\n",
    "def file_info(p):\n",
    "    if not os.path.exists(p):\n",
    "        return {\"path\": p, \"exists\": False}\n",
    "    st = os.stat(p)\n",
    "    return {\n",
    "        \"path\": p,\n",
    "        \"exists\": True,\n",
    "        \"size_bytes\": st.st_size,\n",
    "        \"size_human\": human_size(st.st_size),\n",
    "        \"mtime\": st.st_mtime,\n",
    "    }\n",
    "\n",
    "print(\"文件信息概览：\")\n",
    "for p in [path_adata, path_gene, path_pert]:\n",
    "    print(file_info(p))\n",
    "\n",
    "# 1) 读取 .h5ad\n",
    "print(\"\\n读取 anndata (.h5ad)...\")\n",
    "adata = ad.read_h5ad(path_adata)\n",
    "print(f\"adata: {adata}\")\n",
    "# 尝试预览基本结构\n",
    "print(f\"形状: n_obs={adata.n_obs}, n_vars={adata.n_vars}\")\n",
    "print(\"obs 列（前若干）:\", list(adata.obs.columns)[:10])\n",
    "print(\"var 列（前若干）:\", list(adata.var.columns)[:10])\n",
    "# 若 X 为稀疏矩阵，取少量子集转为密集显示\n",
    "try:\n",
    "    sub = adata[:3, :5].X\n",
    "    if hasattr(sub, \"toarray\"):\n",
    "        sub = sub.toarray()\n",
    "    print(\"X 子集(3x5)示例：\\n\", np.asarray(sub))\n",
    "except Exception as e:\n",
    "    print(\"无法显示 X 子集：\", e)\n",
    "\n",
    "# 3) 读取 gene_names.csv\n",
    "print(\"\\n读取 gene_names.csv ...\")\n",
    "try:\n",
    "    # 自动推断分隔符，如明确为逗号可用 sep=','\n",
    "    genes_df = pd.read_csv(path_gene)\n",
    "    print(\"gene_names.csv 预览：\")\n",
    "    print(genes_df.head())\n",
    "    print(\"列信息：\", genes_df.columns.tolist())\n",
    "    print(\"行数/列数：\", genes_df.shape)\n",
    "except Exception as e:\n",
    "    print(\"读取 gene_names.csv 出错：\", e)\n",
    "\n",
    "# 4) 读取 pert_counts_Validation.csv\n",
    "print(\"\\n读取 pert_counts_Validation.csv ...\")\n",
    "try:\n",
    "    pert_df = pd.read_csv(path_pert)\n",
    "    print(\"pert_counts_Validation.csv 预览：\")\n",
    "    print(pert_df.head())\n",
    "    print(\"列信息：\", pert_df.columns.tolist())\n",
    "    print(\"行数/列数：\", pert_df.shape)\n",
    "except Exception as e:\n",
    "    print(\"读取 pert_counts_Validation.csv 出错：\", e)\n",
    "\n",
    "# 可选：一致性检查（例如基因名是否和 adata.var 索引对齐）\n",
    "try:\n",
    "    if 'gene' in (genes_df.columns if 'genes_df' in locals() else []):\n",
    "        gene_list = genes_df['gene'].astype(str).tolist()\n",
    "        adata_genes = adata.var_names.astype(str).tolist()\n",
    "        overlap = len(set(gene_list) & set(adata_genes))\n",
    "        print(f\"\\n基因名重叠计数：{overlap} / {len(gene_list)}\")\n",
    "except Exception as e:\n",
    "    print(\"一致性检查时出错：\", e)\n",
    "\n",
    "print(\"\\n读取完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adata: AnnData object with n_obs × n_vars = 221273 × 18080\n",
      "    obs: 'target_gene', 'guide_id', 'batch'\n",
      "    var: 'gene_id'\n",
      "obs columns: ['target_gene', 'guide_id', 'batch']\n",
      "var columns: ['gene_id']\n",
      "layers: None\n",
      "obsm: None\n",
      "varm: None\n",
      "uns: None\n",
      "raw: No\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "float32\n",
      "是否为稀疏矩阵: True\n",
      "target_gene: 151 unique values\n",
      "target_gene\n",
      "non-targeting    38176\n",
      "TMSB4X            4760\n",
      "PRCP              4331\n",
      "TADA1             4035\n",
      "HIRA              3407\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "guide_id: 189 unique values\n",
      "guide_id\n",
      "TADA1_P1P2_A|TADA1_P1P2_B    4035\n",
      "PRCP_P1_A|PRCP_P1_B          3415\n",
      "IGF2R_P1P2_A|IGF2R_P1P2_B    3109\n",
      "NCK2_P1P2_A|NCK2_P1P2_B      2929\n",
      "HIRA_P1_A|HIRA_P1_B          2888\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "batch: 48 unique values\n",
      "batch\n",
      "Flex_3_10    5082\n",
      "Flex_3_06    5068\n",
      "Flex_3_15    5038\n",
      "Flex_3_11    4988\n",
      "Flex_3_08    4988\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "                 gene_id\n",
      "SAMD11   ENSG00000187634\n",
      "NOC2L    ENSG00000188976\n",
      "KLHL17   ENSG00000187961\n",
      "PLEKHN1  ENSG00000187583\n",
      "PERM1    ENSG00000187642\n"
     ]
    }
   ],
   "source": [
    "print(f\"adata: {adata}\")\n",
    "print(\"obs columns:\", adata.obs.columns.tolist())\n",
    "print(\"var columns:\", adata.var.columns.tolist())\n",
    "print(\"layers:\", list(adata.layers.keys()) if adata.layers else None)\n",
    "print(\"obsm:\", list(adata.obsm.keys()) if adata.obsm else None)\n",
    "print(\"varm:\", list(adata.varm.keys()) if adata.varm else None)\n",
    "print(\"uns:\", list(adata.uns.keys()) if adata.uns else None)\n",
    "print(\"raw:\", \"Yes\" if adata.raw is not None else \"No\")\n",
    "print(type(adata.X))\n",
    "print(adata.X.dtype)\n",
    "print(\"是否为稀疏矩阵:\", hasattr(adata.X, \"toarray\"))\n",
    "for col in adata.obs.columns:\n",
    "    print(f\"{col}: {adata.obs[col].nunique()} unique values\")\n",
    "    print(adata.obs[col].value_counts().head(), \"\\n\")\n",
    "print(adata.var.head())\n",
    "if \"X_pca\" in adata.obsm:\n",
    "    print(\"PCA shape:\", adata.obsm[\"X_pca\"].shape)\n",
    "\n",
    "if \"X_umap\" in adata.obsm:\n",
    "    print(\"UMAP shape:\", adata.obsm[\"X_umap\"].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset (old version: used for vcc.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target_gene  n_cells\n",
      "0        MED13     2787\n",
      "1        STAT1     2493\n",
      "2        KAT2A     2120\n",
      "3          KDR     2056\n",
      "4        HMGN1     2004\n",
      "5      TSC22D4     1970\n",
      "6         RNF2     1844\n",
      "7        ACAT2     1765\n",
      "8        CREG1     1703\n",
      "9        HMGB2     1487\n",
      "10      DHCR24     1420\n",
      "11      ACVR1B     1400\n",
      "12       DHX36     1392\n",
      "13       LZTR1     1381\n",
      "14       CLDN7     1303\n",
      "15       CENPO     1193\n",
      "16        NRAS     1172\n",
      "17       CHMP3     1168\n",
      "18        EID2     1167\n",
      "19      ZNF426     1132\n",
      "20       PLCB3     1110\n",
      "21        PMS1     1100\n",
      "22     ZNF286A     1059\n",
      "23       PHF14      899\n",
      "24       C1QBP      711\n",
      "25       SIN3B      586\n",
      "26       EWSR1      538\n",
      "27       MED24      455\n",
      "28       KDM1A      352\n",
      "29     SLC39A6      178\n"
     ]
    }
   ],
   "source": [
    "# used for vcc.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "\n",
    "print(\"\\n读取 anndata (.h5ad)...\")\n",
    "adata = ad.read_h5ad(\"adata_Training.h5ad\")\n",
    "print(f\"adata: {adata}\")\n",
    "# 提取所有 target genes（去除 non-targeting）\n",
    "all_targets = adata.obs['target_gene'].unique().tolist()\n",
    "all_targets = [g for g in all_targets if g != \"non-targeting\"]\n",
    "\n",
    "print(\"扰动基因数量：\", len(all_targets))  # 应为 150\n",
    "\n",
    "# 固定随机种子以保证可复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 打乱顺序\n",
    "np.random.shuffle(all_targets)\n",
    "\n",
    "# 划分比例，可根据需要调整\n",
    "val_ratio = 0.3\n",
    "test_ratio = 0.2\n",
    "\n",
    "n = len(all_targets)\n",
    "n_val = int(n * val_ratio)\n",
    "n_test = int(n * test_ratio)\n",
    "\n",
    "val_genes = all_targets[:n_val]\n",
    "test_genes = all_targets[n_val:n_val + n_test]\n",
    "train_genes = all_targets[n_val + n_test:]\n",
    "\n",
    "print(\"Validation genes:\", len(val_genes))\n",
    "print(\"Test genes:\", len(test_genes))\n",
    "print(\"Train genes:\",len(train_genes))\n",
    "# -------------------------\n",
    "# 生成 validation AnnData\n",
    "# -------------------------\n",
    "adata_val = adata[adata.obs['target_gene'].isin(val_genes)].copy()\n",
    "adata_test = adata[adata.obs['target_gene'].isin(test_genes)].copy()\n",
    "adata_train=adata[adata.obs['target_gene'].isin(train_genes)].copy()\n",
    "# # 保存文件（英文文件名）\n",
    "# date=\"1119\"\n",
    "# adata_val.write_h5ad(f\"validation_set_{date}.h5ad\")\n",
    "# adata_test.write_h5ad(f\"test_set_{date}.h5ad\")\n",
    "# adata_train.write_h5ad(f\"training_set_{date}.h5ad\")\n",
    "\n",
    "# print(f\"保存完成：validation_set_{date}.h5ad, test_set_{date}.h5ad, training_set_{date}.h5ad\")\n",
    "# 提取 target_gene 列中的细胞数量\n",
    "target_gene_counts = adata.obs['target_gene'].value_counts()\n",
    "\n",
    "# 筛选出 gene_list 中的基因及其对应的细胞数\n",
    "test_targets = adata_test.obs['target_gene'].unique().tolist()\n",
    "valid_targets = adata_val.obs['target_gene'].unique().tolist()\n",
    "test_gene_counts = target_gene_counts[target_gene_counts.index.isin(test_targets)]\n",
    "valid_gene_counts = target_gene_counts[target_gene_counts.index.isin(valid_targets)]\n",
    "\n",
    "# 将结果转换为 DataFrame 并保存为 CSV\n",
    "test_df = test_gene_counts.reset_index()\n",
    "valid_df = valid_gene_counts.reset_index()\n",
    "test_df.columns = ['target_gene', 'n_cells']\n",
    "valid_df.columns = ['target_gene', 'n_cells']\n",
    "test_df.to_csv(f'test_gene_ncell_{date}.csv', index=False)\n",
    "valid_df.to_csv(f'valid_gene_ncell_{date}.csv', index=False)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "读取 anndata (.h5ad)...\n",
      "adata: AnnData object with n_obs × n_vars = 221273 × 18080\n",
      "    obs: 'target_gene', 'guide_id', 'batch'\n",
      "    var: 'gene_id'\n",
      "扰动基因数量： 150\n",
      "Validation genes: 45\n",
      "Test genes: 30\n",
      "Train genes: 75\n",
      "保存完成：validation_set_1119.h5ad, test_set_1119.h5ad, training_set_1119.h5ad\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "\n",
    "print(\"\\n读取 anndata (.h5ad)...\")\n",
    "adata = ad.read_h5ad(\"adata_Training.h5ad\")\n",
    "print(f\"adata: {adata}\")\n",
    "# 提取所有 target genes（去除 non-targeting）\n",
    "all_targets = adata.obs['target_gene'].unique().tolist()\n",
    "all_targets = [g for g in all_targets if g != \"non-targeting\"]\n",
    "ntc_adata = adata[adata.obs[\"target_gene\"] == \"non-targeting\"] # 添加 non-targeting 控制组\n",
    "\n",
    "print(\"扰动基因数量：\", len(all_targets))  # 应为 150\n",
    "\n",
    "# 固定随机种子以保证可复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 打乱顺序\n",
    "np.random.shuffle(all_targets)\n",
    "\n",
    "# 划分比例，可根据需要调整\n",
    "val_ratio = 0.3\n",
    "test_ratio = 0.2\n",
    "\n",
    "n = len(all_targets)\n",
    "n_val = int(n * val_ratio)\n",
    "n_test = int(n * test_ratio)\n",
    "\n",
    "val_genes = all_targets[:n_val]\n",
    "test_genes = all_targets[n_val:n_val + n_test]\n",
    "train_genes = all_targets[n_val + n_test:]\n",
    "\n",
    "print(\"Validation genes:\", len(val_genes))\n",
    "print(\"Test genes:\", len(test_genes))\n",
    "print(\"Train genes:\",len(train_genes))\n",
    "# -------------------------\n",
    "# 生成 validation AnnData\n",
    "# -------------------------\n",
    "adata_val = adata[adata.obs['target_gene'].isin(val_genes)].copy()\n",
    "adata_test = adata[adata.obs['target_gene'].isin(test_genes)].copy()\n",
    "adata_train=adata[adata.obs['target_gene'].isin(train_genes)].copy()\n",
    "\n",
    "# Append the non-targeting controls to the example anndata if they're missing\n",
    "adata_val=ad.concat([adata_val, ntc_adata])\n",
    "adata_test=ad.concat([adata_test, ntc_adata])\n",
    "adata_train=ad.concat([adata_train, ntc_adata])\n",
    "\n",
    "# 保存文件（英文文件名）\n",
    "date=\"1119\"\n",
    "adata_val.write_h5ad(f\"validation_set_{date}.h5ad\")\n",
    "adata_test.write_h5ad(f\"test_set_{date}.h5ad\")\n",
    "adata_train.write_h5ad(f\"training_set_{date}.h5ad\")\n",
    "\n",
    "print(f\"保存完成：validation_set_{date}.h5ad, test_set_{date}.h5ad, training_set_{date}.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For cell-eval, we need to use log1p data as predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: <class 'scipy.sparse._csr.csr_matrix'> float32 1989.0\n",
      "After: <class 'scipy.sparse._csr.csr_matrix'> float32 5.1971045\n",
      "Saved to eval/..._lognorm.h5ad\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import scanpy as sc\n",
    "\n",
    "def safe_normalize_log1p(file_path):\n",
    "    # \"test_set_1119.h5ad\"\n",
    "    a = ad.read_h5ad(f\"{file_path}.h5ad\")\n",
    "    print(\"Before:\", type(a.X), a.X.dtype, a.X.max())\n",
    "    #  normalize_total + log1p\n",
    "    if sparse.issparse(a.X):\n",
    "        a.X = a.X.astype(np.float32)\n",
    "    else:\n",
    "        a.X = np.asarray(a.X, dtype=np.float32)\n",
    "    sc.pp.normalize_total(a, target_sum=1e4)\n",
    "    sc.pp.log1p(a)\n",
    "    print(\"After:\", type(a.X), a.X.dtype, a.X.max())\n",
    "    a.write_h5ad(f\"eval/{file_path}_lognorm.h5ad\")\n",
    "    print(\"Saved to eval/..._lognorm.h5ad\")\n",
    "\n",
    "#safe_normalize_log1p(\"test_set_1119\")\n",
    "# safe_normalize_log1p(\"training_set_1119\")\n",
    "# safe_normalize_log1p(\"validation_set_1119\")\n",
    "safe_normalize_log1p(\"small_set\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "state1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
